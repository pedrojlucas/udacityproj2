# Udacity Nanodegree Machine Learning Engineer with Azure project 2 (MLOps)

This project is part of the assigments of the Udacity Nanodegree Machine Learning Engineer with Azure. In this case the project is focused in developing all the MLOps phylosohpy using a example case.

In first place we will train a model with a bank marketing dataset, that is intended to find out if a customer will subscribe certain financial product or not. The training of the classification model will be carried out using Azure AutoML. The best model from the AutoML training will be deployed as and endpoint, we will test it with a python script that has attached some dummy data as a json payload.

Finally we will develop a pipeline that will automatize all the previous steps that we have carried out manually: launch of AutoML training and select the best model for deployment as an endpoint.

## Architectural Diagram

![Project Architectural Diagram](/screenshots/Udacity_project2flowdiagram.jpg)

As we can see in the diagram on the left side, we began our project with a csv file that provides us the necessary data for our project. The first thing we need to do is register this data as an Azure dataset. Doing that all the tools available in Azure ML Studio can access to that data.

The following step is to create an Azure ML AutoML experiment for our problem, this is a classification problem where we are going to predict if certain customer is going to subscribe a deposit or not based on different features provided in our data.

Once the AutoML experiment is finished we have several models available, and we can choose a model based on the metrics that best suit our case. Then we can deploy the best model as an endpoint with a URI, it is important to deploy it with authentication enabled to assure that cybersecurity issues will not arise.

The deployed model will provide an API for interaction and to get predictions. We can see how to access this API by taking a look at the documentation generated by Swagger that can be accessed by web browser.

These steps can be automatized using an Azure pipeline, that groups all the steps needed to deploy the best AutoML model from the dataset we have registered in a single workflow. This pipeline can be published and then can be called anytime to replay all the steps and build an AutoML classification model and deploy it as an endpoint.

Finally we can ask the models for predictions, using the URI from the endpoint and the adequate credentials (provided by Azure as primary and secondary keys). The data that the model needs to make its prediction is attached as a payload to the script in json format.

In order to monitor our architecture and model perfomance we can use Apache Benchmarking tool that will give us some metrics oriented to detect bottlenecks in our infraestructure or potential problems with our deployed model prediction processes. 

## Key Steps

![Registered Dataset](/screenshots/Udacity_project2_registereddataset.jpg)

![AutoML completed](/screenshots/Udacity_project2_experimentcompleted.jpg)

![AutoML Best model](/screenshots/Udacity_project2_bestmodel.jpg)

![Model logs]/(/screenshots/Udacity_project2_logsfromendpoint.jpg)

![Model AppInsights](/screenshots/Udacity_project2_appinsights.jpg)

![Swagger API doc](/screenshots/Udacity_project2_swaggerapidoc.jpg)

![Apache Benchmark](/screenshots/Udacity_project2_apache_benchmark.jpg)

*TODO*: Write a short discription of the key steps. Remeber to include all the screenshots required to demonstrate key steps. 

## Screen Recording

https://youtu.be/YJxICUy7xZg

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
